{"expireTime":9007200870884089000,"key":"transformer-remark-markdown-html-3414ac7e735f87c1c956d6245a527349-gatsby-remark-custom-blocks-/SonarQubeChineseDoc8.1","val":"<h2>Checking the logs</h2>\n<p>If you're having trouble starting your server for the first time (or any subsequent time!) the first thing to do is check your server logs. You'll find them in <code>$SONARQUBE_HOME/logs</code>:</p>\n<ul>\n<li>sonar.log - Log for the main process. Holds general information about startup and shutdown. You'll get overall status here but not details. Look to the other logs for that.</li>\n<li>web.log - Information about initial connection to the database, database migration and reindexing, and the processing of HTTP requests. This includes database and search engine logs related to those requests.</li>\n<li>ce.log - Information about background task processing and the database and search engine logs related to those tasks.</li>\n<li>es.log - Ops information from the search engine, such as Elasticsearch startup, health status changes, cluster-, node- and index-level operations, etc.</li>\n</ul>\n<h2>Understanding the logs</h2>\n<p>When there's an error, you'll very often find a stacktrace in the logs. If you're not familiar stacktraces, they can be intimidatingly tall walls of incomprehensible text. As a sample, here's a fairly short one:</p>\n<pre><code>java.lang.IllegalStateException: Unable to blame file **/**/foo.java\n    at org.sonarsource.scm.git.JGitBlameCommand.blame(JGitBlameCommand.java:128)\n    at org.sonarsource.scm.git.JGitBlameCommand.access$000(JGitBlameCommand.java:44)\n    at org.sonarsource.scm.git.JGitBlameCommand$1.call(JGitBlameCommand.java:112)\n    at org.sonarsource.scm.git.JGitBlameCommand$1.call(JGitBlameCommand.java:109)\n    at java.util.concurrent.FutureTask.run(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n    at java.lang.Thread.run(Unknown Source)\nCaused by: java.lang.NullPointerException\n    at org.eclipse.jgit.treewalk.filter.PathFilter.create(PathFilter.java:77)\n    at org.eclipse.jgit.blame.BlameGenerator.&#x3C;init>(BlameGenerator.java:161)\n    at org.eclipse.jgit.api.BlameCommand.call(BlameCommand.java:203)\n    at org.sonarsource.scm.git.JGitBlameCommand.blame(JGitBlameCommand.java:126)\n    ... 7 more\n</code></pre>\n<p>Unless you wrote the code that produced this error, you really only care about:</p>\n<ul>\n<li>the first line, which ought to have a human-readable message after the colon. In this case, it's Unable to blame file <code>**/**/foo.java</code></li>\n<li>and any line that starts with <code>Caused by:</code>. There are often several <code>Caused by</code> lines, and indentation makes them easy to find as you scroll through the error. Be sure to read each of these lines. Very often one of them - the last one or next to last one - contains the real problem.</li>\n</ul>\n<h2>Recovering from Elasticsearch read-only indices</h2>\n<p>You may encounter issues with Elasticsearch (ES) indices becoming locked in read-only mode. ES requires free disk space available and implements a safety mechanism to prevent the disk from being flooded with index data that:</p>\n<ul>\n<li><strong>For non-DCE</strong> –  locks all indices in read-only mode when the 95% used disk usage watermark is reached.  </li>\n<li><strong>For DCE</strong> – locks all or some indices in read-only mode when one or more node reaches the 95% used disk usage watermark.</li>\n</ul>\n<p>ES shows warnings in the logs as soon as disk usage reaches 85% and 90%. At 95% usage and above, indices turning read-only causes errors in the web and compute engine.</p>\n<p>Freeing disk space will <em>not</em> automatically make the indices return to read-write. To make indices read-write, you also need to:</p>\n<ul>\n<li><strong>For non-DCE</strong> – restart SonarQube.</li>\n<li><strong>For DCE</strong> – restart <em>ALL</em> application nodes (the first application node restarted after all have been stopped will make the indices read-write).  </li>\n</ul>\n<p>SonarQube's built-in resilience mechanism allows SonarQube to eventually recover from the indices being behind data in the DB (this process can take a while).</p>\n<p>If you still have inconsistencies, you'll need to rebuild the indices (this operation can take a long time depending on the number of issues and components):</p>\n<p><strong>non-DCE:</strong>  </p>\n<ol>\n<li>Stop SonarQube  </li>\n<li>Delete the data/es6 directory  </li>\n<li>Restart SonarQube  </li>\n</ol>\n<p><strong>DCE:</strong>  </p>\n<ol>\n<li>\n<p>Stop the whole cluster (ES and application nodes)  </p>\n</li>\n<li>\n<p>Delete the data/es6 directory on each ES node  </p>\n</li>\n<li>\n<p>Restart the whole cluster  </p>\n</li>\n</ol>\n<p><strong>Note:</strong> See <a href=\"/SonarQubeChineseDoc8.1/setup/operate-cluster/\">Configure &#x26; Operate a Cluster</a> for information on stopping and starting a cluster.</p>"}